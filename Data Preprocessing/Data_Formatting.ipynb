{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1iQru4lmj9UpIQrqqjLiZ0b5SQs7yopQn",
      "authorship_tag": "ABX9TyNgN54e/eMRqdHsV0MNuNaw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/n1lays1ngh/Delhi-Air-Quality-Prediction/blob/main/Data_Formatting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6fM6UyWZgWt",
        "outputId": "94df4be7-8bd0-46fa-d508-2b4ec434895d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "BK4OpOvre79s"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder_path = '/content/drive/MyDrive/Pollutant Data'\n",
        "\n",
        "# Check if the folder exists to make sure the path is correct\n",
        "if os.path.exists(data_folder_path):\n",
        "    print(f\"Success! Folder found at: {data_folder_path}\")\n",
        "    print(\"You can now run Cell 2.\")\n",
        "else:\n",
        "    print(f\"Error: Folder not found at '{data_folder_path}'\")\n",
        "    print(\"Please double-check the folder name (it's case-sensitive) and path.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WJ3R4rTfcHL",
        "outputId": "a228d2e6-b2a1-4861-a0e0-04520489e8d7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success! Folder found at: /content/drive/MyDrive/Pollutant Data\n",
            "You can now run Cell 2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os # This is needed for os.path.join\n",
        "\n",
        "# --- Configuration ---\n",
        "\n",
        "# Define the 12 months in order. This is crucial for melting.\n",
        "MONTHS_ORDER = [\n",
        "    'January', 'February', 'March', 'April', 'May', 'June',\n",
        "    'July', 'August', 'September', 'October', 'November', 'December'\n",
        "]\n",
        "\n",
        "# Define the years you have data for\n",
        "YEARS = range(2017, 2026) # Goes from 2017 up to 2025\n",
        "\n",
        "# --- Helper Function to Process Each File ---\n",
        "\n",
        "def process_data_file(filepath, year, data_type_name):\n",
        "    \"\"\"\n",
        "    Reads one of your CSV files, unpivots it, and formats it.\n",
        "\n",
        "    filepath: Path to the data file (e.g., 'aqi_2017.csv')\n",
        "    year: The integer year for this data\n",
        "    data_type_name: The name for the value column ('AQI' or 'Pollutants')\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # --- 1. Read the Data ---\n",
        "        df = pd.read_csv(filepath)\n",
        "\n",
        "        # --- 2. Rename 'Day' column (or confirm it) ---\n",
        "        if 'Date' in df.columns:\n",
        "            df = df.rename(columns={'Date': 'Day'})\n",
        "\n",
        "        # --- 3. Unpivot (Melt) the Data ---\n",
        "        df_melted = df.melt(\n",
        "            id_vars=['Day'],\n",
        "            value_vars=MONTHS_ORDER,\n",
        "            var_name='Month',\n",
        "            value_name=data_type_name\n",
        "        )\n",
        "\n",
        "        # --- 4. Create the Full Date Column ---\n",
        "        df_melted['Year'] = year\n",
        "\n",
        "        # Combine Day, Month, and Year into a single string\n",
        "        date_str = df_melted['Day'].astype(str) + '-' + \\\n",
        "                     df_melted['Month'] + '-' + \\\n",
        "                     df_melted['Year'].astype(str)\n",
        "\n",
        "        # Convert the string into a proper datetime object\n",
        "        df_melted['Date'] = pd.to_datetime(date_str, format='%d-%B-%Y', errors='coerce')\n",
        "\n",
        "        # --- 5. Clean and Finalize ---\n",
        "        df_melted = df_melted.dropna(subset=['Date'])\n",
        "        final_df = df_melted[['Date', data_type_name]]\n",
        "\n",
        "        return final_df\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Warning: File not found, skipping: {filepath}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing file {filepath}: {e}\")\n",
        "        return None\n",
        "\n",
        "# --- Main Script to Process All Files ---\n",
        "\n",
        "# Retrieve the folder path defined in Cell 1\n",
        "# (This assumes Cell 1 has been run)\n",
        "try:\n",
        "    data_folder_path\n",
        "except NameError:\n",
        "    print(\"Error: 'data_folder_path' is not defined.\")\n",
        "    print(\"Please run Cell 1 first to mount Google Drive.\")\n",
        "    # Stop the script if the path isn't defined\n",
        "    raise\n",
        "\n",
        "print(\"Starting data reformatting...\")\n",
        "all_processed_dfs = []\n",
        "\n",
        "for year in YEARS:\n",
        "    print(f\"--- Processing Year: {year} ---\")\n",
        "\n",
        "    # Define the expected file paths using the Google Drive folder path\n",
        "    aqi_file = os.path.join(data_folder_path, f'aqi_{year}.csv')\n",
        "    pollutants_file = os.path.join(data_folder_path, f'pollutants_{year}.csv')\n",
        "\n",
        "    # Process the AQI file for the year\n",
        "    aqi_df = None\n",
        "    if os.path.exists(aqi_file):\n",
        "        aqi_df = process_data_file(aqi_file, year, 'AQI')\n",
        "    else:\n",
        "        print(f\"No AQI file found for {year}.\")\n",
        "\n",
        "    # Process the Pollutants file (if it exists)\n",
        "    pollutants_df = None\n",
        "    if os.path.exists(pollutants_file):\n",
        "        pollutants_df = process_data_file(pollutants_file, year, 'Pollutants')\n",
        "    else:\n",
        "        print(f\"No Pollutants file found for {year}.\")\n",
        "\n",
        "    # --- Combine the year's data ---\n",
        "    if aqi_df is not None and pollutants_df is not None:\n",
        "        year_df = pd.merge(aqi_df, pollutants_df, on='Date', how='outer')\n",
        "        all_processed_dfs.append(year_df)\n",
        "    elif aqi_df is not None:\n",
        "        all_processed_dfs.append(aqi_df)\n",
        "    elif pollutants_df is not None:\n",
        "        all_processed_dfs.append(pollutants_df)\n",
        "\n",
        "# --- Final Combination ---\n",
        "if all_processed_dfs:\n",
        "    final_data = pd.concat(all_processed_dfs)\n",
        "    final_data = final_data.sort_values(by='Date').reset_index(drop=True)\n",
        "\n",
        "    # --- Save the Result ---\n",
        "    # We save the final file back to your Google Drive folder\n",
        "    output_filename = os.path.join(data_folder_path, 'delhi_aqi_timeseries_formatted.csv')\n",
        "    final_data.to_csv(output_filename, index=False)\n",
        "\n",
        "    print(\"\\n--- Success! ---\")\n",
        "    print(f\"All data processed and saved to: '{output_filename}'\")\n",
        "\n",
        "    print(\"\\nFirst 5 rows of formatted data:\")\n",
        "    print(final_data.head())\n",
        "\n",
        "    print(\"\\nLast 5 rows of formatted data:\")\n",
        "    print(final_data.tail())\n",
        "\n",
        "    print(\"\\nData Info:\")\n",
        "    final_data.info()\n",
        "else:\n",
        "    print(\"\\nNo data was processed. Please check your file paths and configuration.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DznyqKe9feMF",
        "outputId": "0e685f58-d524-4ffa-9186-6b2694fcd5cc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting data reformatting...\n",
            "--- Processing Year: 2017 ---\n",
            "No Pollutants file found for 2017.\n",
            "--- Processing Year: 2018 ---\n",
            "No Pollutants file found for 2018.\n",
            "--- Processing Year: 2019 ---\n",
            "No Pollutants file found for 2019.\n",
            "--- Processing Year: 2020 ---\n",
            "No Pollutants file found for 2020.\n",
            "--- Processing Year: 2021 ---\n",
            "--- Processing Year: 2022 ---\n",
            "--- Processing Year: 2023 ---\n",
            "--- Processing Year: 2024 ---\n",
            "--- Processing Year: 2025 ---\n",
            "Error processing file /content/drive/MyDrive/Pollutant Data/aqi_2025.csv: \"The following id_vars or value_vars are not present in the DataFrame: ['April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\"\n",
            "Error processing file /content/drive/MyDrive/Pollutant Data/pollutants_2025.csv: \"The following id_vars or value_vars are not present in the DataFrame: ['April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\"\n",
            "\n",
            "--- Success! ---\n",
            "All data processed and saved to: '/content/drive/MyDrive/Pollutant Data/delhi_aqi_timeseries_formatted.csv'\n",
            "\n",
            "First 5 rows of formatted data:\n",
            "        Date    AQI Pollutants\n",
            "0 2017-01-01  345.0        NaN\n",
            "1 2017-01-02  337.0        NaN\n",
            "2 2017-01-03  331.0        NaN\n",
            "3 2017-01-04  381.0        NaN\n",
            "4 2017-01-05  321.0        NaN\n",
            "\n",
            "Last 5 rows of formatted data:\n",
            "           Date    AQI  Pollutants\n",
            "2917 2024-12-27  353.0  PM10,PM2.5\n",
            "2918 2024-12-28  139.0  PM10,PM2.5\n",
            "2919 2024-12-29  225.0  PM10,PM2.5\n",
            "2920 2024-12-30  173.0  PM10,PM2.5\n",
            "2921 2024-12-31  283.0  PM10,PM2.5\n",
            "\n",
            "Data Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2922 entries, 0 to 2921\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype         \n",
            "---  ------      --------------  -----         \n",
            " 0   Date        2922 non-null   datetime64[ns]\n",
            " 1   AQI         2889 non-null   float64       \n",
            " 2   Pollutants  1461 non-null   object        \n",
            "dtypes: datetime64[ns](1), float64(1), object(1)\n",
            "memory usage: 68.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os # This is needed for os.path.join\n",
        "\n",
        "# --- Configuration ---\n",
        "\n",
        "# Define the 12 months in order. This is crucial for melting.\n",
        "MONTHS_ORDER = [\n",
        "    'January', 'February', 'March', 'April', 'May', 'June',\n",
        "    'July', 'August', 'September', 'October', 'November', 'December'\n",
        "]\n",
        "\n",
        "# Define the years you have data for\n",
        "YEARS = range(2017, 2026) # Goes from 2017 up to 2025\n",
        "\n",
        "# --- Helper Function to Process Each File ---\n",
        "\n",
        "def process_data_file(filepath, year, data_type_name):\n",
        "    \"\"\"\n",
        "    Reads one of your CSV files, unpivots it, and formats it.\n",
        "\n",
        "    filepath: Path to the data file (e.g., 'aqi_2017.csv')\n",
        "    year: The integer year for this data\n",
        "    data_type_name: The name for the value column ('AQI' or 'Pollutants')\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # --- 1. Read the Data ---\n",
        "        df = pd.read_csv(filepath)\n",
        "\n",
        "        # --- 2. Rename 'Day' column (or confirm it) ---\n",
        "        if 'Date' in df.columns:\n",
        "            df = df.rename(columns={'Date': 'Day'})\n",
        "\n",
        "        # --- 3. Unpivot (Melt) the Data ---\n",
        "\n",
        "        # --- THIS IS THE FIX ---\n",
        "        # Instead of using the full MONTHS_ORDER, we find which months\n",
        "        # from that list *actually exist* as columns in the current file.\n",
        "        months_to_melt = [month for month in MONTHS_ORDER if month in df.columns]\n",
        "\n",
        "        # If we didn't find any valid month columns, skip the file.\n",
        "        if not months_to_melt:\n",
        "            print(f\"Warning: No valid month columns found in {filepath}. Skipping.\")\n",
        "            return None\n",
        "\n",
        "        # Now, we melt *only* the months that were found.\n",
        "        df_melted = df.melt(\n",
        "            id_vars=['Day'],\n",
        "            value_vars=months_to_melt, # <-- This list is now dynamic\n",
        "            var_name='Month',\n",
        "            value_name=data_type_name\n",
        "        )\n",
        "        # --- END OF FIX ---\n",
        "\n",
        "        # --- 4. Create the Full Date Column ---\n",
        "        df_melted['Year'] = year\n",
        "\n",
        "        # Combine Day, Month, and Year into a single string\n",
        "        date_str = df_melted['Day'].astype(str) + '-' + \\\n",
        "                     df_melted['Month'] + '-' + \\\n",
        "                     df_melted['Year'].astype(str)\n",
        "\n",
        "        # Convert the string into a proper datetime object\n",
        "        df_melted['Date'] = pd.to_datetime(date_str, format='%d-%B-%Y', errors='coerce')\n",
        "\n",
        "        # --- 5. Clean and Finalize ---\n",
        "        df_melted = df_melted.dropna(subset=['Date'])\n",
        "        final_df = df_melted[['Date', data_type_name]]\n",
        "\n",
        "        return final_df\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Warning: File not found, skipping: {filepath}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing file {filepath}: {e}\")\n",
        "        return None\n",
        "\n",
        "# --- Main Script to Process All Files ---\n",
        "\n",
        "# Retrieve the folder path defined in Cell 1\n",
        "try:\n",
        "    data_folder_path\n",
        "except NameError:\n",
        "    print(\"Error: 'data_folder_path' is not defined.\")\n",
        "    print(\"Please run Cell 1 first to mount Google Drive.\")\n",
        "    # Stop the script if the path isn't defined\n",
        "    raise\n",
        "\n",
        "print(\"Starting data reformatting...\")\n",
        "all_processed_dfs = []\n",
        "\n",
        "for year in YEARS:\n",
        "    print(f\"--- Processing Year: {year} ---\")\n",
        "\n",
        "    # Define the expected file paths using the Google Drive folder path\n",
        "    aqi_file = os.path.join(data_folder_path, f'aqi_{year}.csv')\n",
        "    pollutants_file = os.path.join(data_folder_path, f'pollutants_{year}.csv')\n",
        "\n",
        "    # Process the AQI file for the year\n",
        "    aqi_df = None\n",
        "    if os.path.exists(aqi_file):\n",
        "        aqi_df = process_data_file(aqi_file, year, 'AQI')\n",
        "    else:\n",
        "        print(f\"No AQI file found for {year}.\")\n",
        "\n",
        "    # Process the Pollutants file (if it exists)\n",
        "    pollutants_df = None\n",
        "    if os.path.exists(pollutants_file):\n",
        "        pollutants_df = process_data_file(pollutants_file, year, 'Pollutants')\n",
        "    else:\n",
        "        print(f\"No Pollutants file found for {year}.\")\n",
        "\n",
        "    # --- Combine the year's data ---\n",
        "    if aqi_df is not None and pollutants_df is not None:\n",
        "        year_df = pd.merge(aqi_df, pollutants_df, on='Date', how='outer')\n",
        "        all_processed_dfs.append(year_df)\n",
        "    elif aqi_df is not None:\n",
        "        all_processed_dfs.append(aqi_df)\n",
        "    elif pollutants_df is not None:\n",
        "        all_processed_dfs.append(pollutants_df)\n",
        "\n",
        "# --- Final Combination ---\n",
        "if all_processed_dfs:\n",
        "    final_data = pd.concat(all_processed_dfs)\n",
        "    final_data = final_data.sort_values(by='Date').reset_index(drop=True)\n",
        "\n",
        "    # --- Save the Result ---\n",
        "    # We save the final file back to your Google Drive folder\n",
        "    output_filename = os.path.join(data_folder_path, 'delhi_aqi_timeseries_formatted2.csv')\n",
        "    final_data.to_csv(output_filename, index=False)\n",
        "\n",
        "    print(\"\\n--- Success! ---\")\n",
        "    print(f\"All data processed and saved to: '{output_filename}'\")\n",
        "\n",
        "    print(\"\\nFirst 5 rows of formatted data:\")\n",
        "    print(final_data.head())\n",
        "\n",
        "    print(\"\\nLast 5 rows of formatted data:\")\n",
        "    print(final_data.tail())\n",
        "\n",
        "    print(\"\\nData Info:\")\n",
        "    final_data.info()\n",
        "else:\n",
        "    print(\"\\nNo data was processed. Please check your file paths and configuration.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McoaRHw1fhko",
        "outputId": "3f6c8e7b-a1f9-4173-fa91-da677f4fd039"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting data reformatting...\n",
            "--- Processing Year: 2017 ---\n",
            "No Pollutants file found for 2017.\n",
            "--- Processing Year: 2018 ---\n",
            "No Pollutants file found for 2018.\n",
            "--- Processing Year: 2019 ---\n",
            "No Pollutants file found for 2019.\n",
            "--- Processing Year: 2020 ---\n",
            "No Pollutants file found for 2020.\n",
            "--- Processing Year: 2021 ---\n",
            "--- Processing Year: 2022 ---\n",
            "--- Processing Year: 2023 ---\n",
            "--- Processing Year: 2024 ---\n",
            "--- Processing Year: 2025 ---\n",
            "\n",
            "--- Success! ---\n",
            "All data processed and saved to: '/content/drive/MyDrive/Pollutant Data/delhi_aqi_timeseries_formatted2.csv'\n",
            "\n",
            "First 5 rows of formatted data:\n",
            "        Date    AQI Pollutants\n",
            "0 2017-01-01  345.0        NaN\n",
            "1 2017-01-02  337.0        NaN\n",
            "2 2017-01-03  331.0        NaN\n",
            "3 2017-01-04  381.0        NaN\n",
            "4 2017-01-05  321.0        NaN\n",
            "\n",
            "Last 5 rows of formatted data:\n",
            "           Date    AQI      Pollutants\n",
            "3007 2025-03-27  259.0      PM10,PM2.5\n",
            "3008 2025-03-28  205.0  NO2,OZONE,PM10\n",
            "3009 2025-03-29  153.0    CO,NO2,OZONE\n",
            "3010 2025-03-30  138.0    CO,NO2,OZONE\n",
            "3011 2025-03-31  160.0    CO,NO2,OZONE\n",
            "\n",
            "Data Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3012 entries, 0 to 3011\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype         \n",
            "---  ------      --------------  -----         \n",
            " 0   Date        3012 non-null   datetime64[ns]\n",
            " 1   AQI         2979 non-null   float64       \n",
            " 2   Pollutants  1551 non-null   object        \n",
            "dtypes: datetime64[ns](1), float64(1), object(1)\n",
            "memory usage: 70.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D9jOhCLcgIeJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}